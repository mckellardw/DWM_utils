########################################################################################################
# 10x_STARsolo
#   Snakemake workflow to use STARsolo to align and quantify 10x Chromium datasets
#   v1.0
#   Written by David McKellar
########################################################################################################

import pandas as pd
import scipy.io
import scipy.sparse

########################################################################################################
# Config file
########################################################################################################
configfile:'config.yaml'
CHEMISTRY_SHEET = pd.read_csv(config["CHEMISTRY_SHEET"], na_filter=False,index_col=0) #"resources/chemistry_sheet.csv"
########################################################################################################
# Directories and locations
########################################################################################################
TMPDIR = config['TMPDIR']
OUTDIR = config['OUTDIR']

########################################################################################################
# Variables and references
########################################################################################################
SAMPLE_SHEET = pd.read_csv(config["SAMPLE_SHEET_PATH"], na_filter=False)
SAMPLES = list(SAMPLE_SHEET['sampleID'])

R1_FQS = dict(zip(SAMPLES, list(SAMPLE_SHEET['fastq_R1'])))
R2_FQS = dict(zip(SAMPLES, list(SAMPLE_SHEET['fastq_R2'])))


########################################################################################################
# Executables
########################################################################################################
STAR_EXEC = config["STAR_EXEC"]
# GGET_EXEC = config["GGET_EXEC"]
FASTQC_EXEC = config["FASTQC_EXEC"]
# TRIMGALORE_EXEC = config["TRIMGALORE_EXEC"]
CUTADAPT_EXEC = config["CUTADAPT_EXEC"]
SAMTOOLS_EXEC = config["SAMTOOLS_EXEC"]
UMITOOLS_EXEC = config["UMITOOLS_EXEC"]
QUALIMAP_EXEC = config["QUALIMAP_EXEC"]

########################################################################################################
# Pre-run setup
########################################################################################################
# Build dictionaries of chemistries & species to use for alignment
CHEM_DICT = {}
REF_DICT = {}
IDX_DICT = {}
T2G_DICT = {}
BB_DICT = {}
GTF_DICT = {}
for i in range(0,SAMPLE_SHEET.shape[0]):
    tmp_sample = list(SAMPLE_SHEET["sampleID"])[i]
    CHEM_DICT[tmp_sample] = list(SAMPLE_SHEET["chemistry"])[i]
    REF_DICT[tmp_sample] = list(SAMPLE_SHEET["STAR_ref"])[i]
    IDX_DICT[tmp_sample] = list(SAMPLE_SHEET["kb_idx"])[i]
    T2G_DICT[tmp_sample] = list(SAMPLE_SHEET["kb_t2g"])[i]
    BB_DICT[tmp_sample] = list(SAMPLE_SHEET["BB_map"])[i]
    GTF_DICT[tmp_sample] = list(SAMPLE_SHEET["genes_gtf"])[i]

########################################################################################################
rule all:
    input:
        # expand('{OUTDIR}/{sample}/STARsolo/Solo.out/Gene/raw/matrix.mtx.gz', OUTDIR=config['OUTDIR'], sample=SAMPLES), #STAR count mats
        expand('{OUTDIR}/{sample}/kb/counts_unfiltered/output.mtx', OUTDIR=config['OUTDIR'], sample=SAMPLES), #kallisto count mats
        # expand('{OUTDIR}/{sample}/STARsolo/Solo.out/Gene/raw_feature_bc_matrix_h5.h5', OUTDIR=config['OUTDIR'], sample=SAMPLES),
        expand('{OUTDIR}/{sample}/qualimap/qualimapReport.html', OUTDIR=config['OUTDIR'], sample=SAMPLES), # alignment QC qith qualimap | requires deduped input!
        # expand('{OUTDIR}/{sample}/STARsolo/Aligned.sortedByCoord.dedup.out.bam.bai', OUTDIR=config['OUTDIR'], sample=SAMPLES), # umi_tools deduplicated .bam
        # expand('{OUTDIR}/{sample}/STARsolo/Aligned.sortedByCoord.dedup.out_plus.bw', OUTDIR=config['OUTDIR'], sample=SAMPLES), # strand-split bigWigs
        # expand('{OUTDIR}/{sample}/STARsolo/Aligned.sortedByCoord.dedup.out_merged.bw', OUTDIR=config['OUTDIR'], sample=SAMPLES), #
        expand('{OUTDIR}/{sample}/preTrim_fastqc_R2_out', OUTDIR=config['OUTDIR'], sample=SAMPLES), # raw R2 fastQC results
        expand('{OUTDIR}/{sample}/postTrim_fastqc_R2_out', OUTDIR=config['OUTDIR'], sample=SAMPLES), # adapter/polyA/ployG-trimmed R2 fastQC results
        expand('{OUTDIR}/{sample}/cutadapt.log', OUTDIR=config['OUTDIR'], sample=SAMPLES),
        expand('{OUTDIR}/{sample}/STARsolo/Aligned.sortedByCoord.out.bam.bai', OUTDIR=config['OUTDIR'], sample=SAMPLES), #non-deduplicated .bam; used for saturation estimation
        expand('{OUTDIR}/{sample}/Unmapped_fastqc_out', OUTDIR=config['OUTDIR'], sample=SAMPLES), #fastQC results for unmapped reads
        expand('{OUTDIR}/{sample}/Unmapped.out.mate2_blastResults.txt', OUTDIR=config['OUTDIR'], sample=SAMPLES), # blastn results for unmapped R1 reads non-strand-split bigWigs (for

#############################################
## Pre-alignment set up
#############################################
# Unzip the whitelist file if it hasn't been done yet
rule splitBBList:
    input:
        BB_map = lambda wildcards: BB_DICT[wildcards.sample]
    output:
        BB = "{OUTDIR}/{sample}/tmp/whitelist.txt",
        BB_1 = "{OUTDIR}/{sample}/tmp/whitelist_1.txt",
        BB_2 = "{OUTDIR}/{sample}/tmp/whitelist_2.txt"
    run:
        #load bc
        bc_df = pd.read_csv(input.BB_map, sep="\t", header=None).iloc[:,0]

        # split for 2 separate barcodes
        bc_1 = pd.DataFrame(bc[0:8] for bc in list(bc_df.values))
        bc_2 = pd.DataFrame(bc[8:14] for bc in list(bc_df.values))

        # save bc files in {sample}/tmp
        bc_df.to_csv(output.BB, sep="\t", header=False, index=False) # Full bead barcode
        bc_1.to_csv(output.BB_1, sep="\t", header=False, index=False) # Bead barcode #1
        bc_2.to_csv(output.BB_2, sep="\t", header=False, index=False) # Bead Barcode #2

#############################################
## Trimming and FastQC
#############################################

# Merge .fastq files (in case more than one sesquencing run was performed)
rule merge_fastqs:
    output:
        MERGED_R1_FQ = temp('{OUTDIR}/{sample}/tmp/{sample}_R1.fq.gz'),
        MERGED_R2_FQ = temp('{OUTDIR}/{sample}/tmp/{sample}_R2.fq.gz')
    params:
        TMP_DIR = '{OUTDIR}/{sample}/tmp',
        R1_FQ = lambda wildcards: R1_FQS[wildcards.sample],
        R2_FQ = lambda wildcards: R2_FQS[wildcards.sample]
    threads:
        config['CORES']
    # conda:
    #     "STARsolo"
    run:
        if len(params.R1_FQ.split(" "))==1 & len(params.R2_FQ.split(" "))==1: # shell for single fastq input
            shell("cp {params.R1_FQ} {output.MERGED_R1_FQ}")
            shell("cp {params.R2_FQ} {output.MERGED_R2_FQ}")
        else: # shell enablinging multi-fast input; concatenate inputs
            print("Concatenating",len(params.R1_FQ.split(" ")), ".fastq's for", wildcards.sample)
            shell("mkdir -p {params.TMP_DIR}")
            shell("zcat {params.R1_FQ} > {params.TMP_DIR}/{wildcards.sample}_R1.fq")
            shell("zcat {params.R2_FQ} > {params.TMP_DIR}/{wildcards.sample}_R2.fq")
            shell("pigz -p {threads} {params.TMP_DIR}/*.fq")

rule preTrim_FastQC_R2:
    input:
        MERGED_R2_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R2.fq.gz'
    output:
        fastqcDir = directory('{OUTDIR}/{sample}/preTrim_fastqc_R2_out'),
        # fastqcReport = ''
    threads:
        config['CORES']
        # min([config['CORES'],8]) # 8 core max based on recommendations from trim_galore authors
    shell:
        """
        mkdir -p {output.fastqcDir}
        cd {output.fastqcDir}

        fastqc \
        --outdir {output.fastqcDir} \
        --threads {threads} \
        -a /home/dwm269/DWM_utils/align_pipes/curio_kallisto/resources/fastqc_adapters.txt \
        {input.MERGED_R2_FQ}
        """

# TSO & polyA trimming
# rule trimPolyA_R2:
#     input:
#         MERGED_R1_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R1.fq.gz',
#         MERGED_R2_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R2.fq.gz'
#     output:
#         A_TRIMMED_R1_FQ = temp('{OUTDIR}/{sample}/tmp/{sample}_R1_Atrimmed.fq.gz'),
#         A_TRIMMED_R2_FQ = temp('{OUTDIR}/{sample}/tmp/{sample}_R2_Atrimmed.fq.gz')
#     params:
#         CUTADAPT_EXEC = CUTADAPT_EXEC,
#         THREE_PRIME_R2_POLYA = "A"*100,
#         # FIVE_PRIME_R2 = "CCCATTCACTCTGCGTTGATACCACTGCTT" #10x TSO sequence
#         # FIVE_PRIME_R2 = "TTCGTCACCATAGTTGCGTCTCATGTACCC" #rev 10x TSO sequence
#         FIVE_PRIME_R2 = "AAGCTGGTATCAACGCAGAGTGAATGGG" # SLideSeq TSO
#     threads:
#         config['CORES']
#         # min([config['CORES'],8]) # 8 core max based on recommendations from trim_galore authors
#     log:
#         '{OUTDIR}/{sample}/cutadapt_polyA_report.txt'
#     conda:
#         "STARsolo"
#     shell:
#         """
#         {params.CUTADAPT_EXEC} \
#         --minimum-length 12 \
#         -A {params.THREE_PRIME_R2_POLYA} \
#         --pair-filter=any \
#  		-o {output.A_TRIMMED_R1_FQ} \
#         -p {output.A_TRIMMED_R2_FQ} \
#         --cores {threads} \
#         {input.MERGED_R1_FQ} {input.MERGED_R2_FQ} 1> {log}
#         """

rule cutadapt_R2:
    input:
        TRIMMED_R1_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R1.fq.gz',
        TRIMMED_R2_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R2.fq.gz'
    output:
        FINAL_R1_FQ = temp('{OUTDIR}/{sample}/tmp/{sample}_R1_adapterTrim.fq.gz'),
        FINAL_R2_FQ = temp('{OUTDIR}/{sample}/tmp/{sample}_R2_final.fq.gz')
    params:
        CUTADAPT_EXEC = CUTADAPT_EXEC,
        THREE_PRIME_R2_POLYA = "A"*100,
        THREE_PRIME_R2_POLYG = "G"*100,
        THREE_PRIME_R2_NEXTERA = "CTGTCTCTTATA", # Nextera sequence
        THREE_PRIME_R2_rcNEXTERA = "TATAAGAGACAG", # Rev Comp of Nextera sequence
        THREE_PRIME_R2_TSO = "AAGCTGGTATCAACGCAGAGTGAATGGG", # SlideSeq TSO - remove any polyadenylated TSOs
        THREE_PRIME_R2_ILLUMINA_UNI = "AGATCGGAAGAG", # Illumina Universal
        FIVE_PRIME_R2_TSO = "CCCATTCACTCTGCGTTGATACCAGCTT" # rev comp of SlideSeq TSO
    threads:
        config['CORES']
        # min([config['CORES'],8]) # 8 core max based on recommendations from trim_galore authors
    log:
        log = '{OUTDIR}/{sample}/cutadapt.log'
    shell:
        """
        {params.CUTADAPT_EXEC} \
        --minimum-length 50:16 \
        --quality-cutoff 20 \
        --overlap 3 \
        --match-read-wildcards \
        --nextseq-trim=20 \
        -A {params.THREE_PRIME_R2_POLYA} \
        -A {params.THREE_PRIME_R2_TSO} \
        -A {params.THREE_PRIME_R2_NEXTERA} \
        -A {params.THREE_PRIME_R2_rcNEXTERA} \
        -A {params.THREE_PRIME_R2_ILLUMINA_UNI} \
        -G {params.FIVE_PRIME_R2_TSO} \
        --pair-filter=any \
 		-o {output.FINAL_R1_FQ} \
        -p {output.FINAL_R2_FQ} \
        --cores {threads} \
        {input.TRIMMED_R1_FQ} {input.TRIMMED_R2_FQ} 1> {log.log}
        """
        # -A {params.THREE_PRIME_R2_POLYG}X \

# R1 trimming to remove the
## Source: https://unix.stackexchange.com/questions/510164/remove-and-add-sequence-information-at-specific-position-in-a-file
rule removeLinker_R1:
    input:
        R1_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R1_adapterTrim.fq.gz'
    output:
        FINAL_R1_FQ = temp('{OUTDIR}/{sample}/tmp/{sample}_R1_final.fq.gz')
    params:
        script = "scripts/linkerRemove_R1.awk",
        linkerStart = 9,
        linkerStop = 26
    threads:
        config['CORES']
    run:
        shell(
            f"""
            zcat {input.R1_FQ} | \
            awk -v s={params.linkerStart} -v S={params.linkerStop} -f {params.script} > {OUTDIR}/{wildcards.sample}/tmp/{wildcards.sample}_R1_final.fq

            pigz -p{threads} {OUTDIR}/{wildcards.sample}/tmp/{wildcards.sample}_R1_final.fq
            """
        )

# rule trim_galore:
    # input:
    #     CUT_R1_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R1_final.fq.gz',
    #     CUT_R2_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R2_final.fq.gz'
    # output:
    #     FINAL_R1_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R1_final_val_1.fq.gz',
    #     FINAL_R2_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R2_final_val_2.fq.gz',
    #     TRIM_REPORT = '{OUTDIR}/{sample}/trim_galore_report.txt'
    # params:
    #     OUTDIR = '{OUTDIR}/{sample}/tmp',
    #     TG_EXEC = config["TRIMGALORE_EXEC"]
    # threads:
    #     config['CORES']
    # shell:
    #     """
    #     {params.TG_EXEC} \
    #     --paired \
    #     --length 12 \
    #     --quality 30 \
    #     -o {params.OUTDIR} \
    #     --cores {threads} \
    #     {input.CUT_R1_FQ} {input.CUT_R2_FQ}
    #
    #     mv {params.OUTDIR}/{wildcards.sample}_R2_final.fq.gz_trimming_report.txt {output.TRIM_REPORT}
    #     """

rule postTrim_FastQC_R2:
    input:
        FINAL_R2_FQ =  '{OUTDIR}/{sample}/tmp/{sample}_R2_final.fq.gz'
    output:
        fastqcDir = directory('{OUTDIR}/{sample}/postTrim_fastqc_R2_out'),
        # fastqcReport = ''
    threads:
        config['CORES']
        # min([config['CORES'],8]) # 8 core max based on recommendations from trim_galore authors
    conda:
        "STARsolo"
    shell:
        """
        mkdir -p {output.fastqcDir}
        cd {output.fastqcDir}

        fastqc \
        --outdir {output.fastqcDir} \
        --threads {threads} \
        -a /home/dwm269/DWM_utils/align_pipes/curio_kallisto/resources/fastqc_adapters.txt \
        {input.FINAL_R2_FQ}
        """

#############################################
## STAR Alignment
#############################################
# Make output directory, align fastqs, and generate raw/filtered feature/cell-barcode matrices
#   Info for STARsolo command line paramaters: https://github.com/alexdobin/STAR/blob/master/docs/STARsolo.md

rule STARsolo_align:
    input:
        FINAL_R1_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R1_final.fq.gz',
        FINAL_R2_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R2_final.fq.gz',
        BB_WHITELIST = "{OUTDIR}/{sample}/tmp/whitelist.txt",
        BB_2 = "{OUTDIR}/{sample}/tmp/whitelist_2.txt"
    output:
        SORTEDBAM = '{OUTDIR}/{sample}/STARsolo/Aligned.sortedByCoord.out.bam', #TODO: add temp()
        UNMAPPED1 = '{OUTDIR}/{sample}/STARsolo/Unmapped.out.mate1',
        UNMAPPED2 = '{OUTDIR}/{sample}/STARsolo/Unmapped.out.mate2',
        GENE = directory('{OUTDIR}/{sample}/STARsolo/Solo.out/Gene'),
        GENEFULL = directory('{OUTDIR}/{sample}/STARsolo/Solo.out/GeneFull'),
        # SJ = directory('{OUTDIR}/{sample}/STARsolo/Solo.out/SJ'),
        VEL = directory('{OUTDIR}/{sample}/STARsolo/Solo.out/Velocyto'),
        GENEMAT = '{OUTDIR}/{sample}/STARsolo/Solo.out/Gene/raw/matrix.mtx',
        GENEFULLMAT = '{OUTDIR}/{sample}/STARsolo/Solo.out/GeneFull/raw/matrix.mtx',
        # SJMAT = '{OUTDIR}/{sample}/STARsolo/Solo.out/SJ/raw/matrix.mtx',
        VELMAT = '{OUTDIR}/{sample}/STARsolo/Solo.out/Velocyto/raw/spliced.mtx'
    params:
        OUTDIR = config['OUTDIR'],
        STAR_EXEC = config['STAR_EXEC'],
        MEMLIMIT = config['MEMLIMIT']
    threads:
        config['CORES']
    priority:
        42
    # conda:
    #     "STARsolo"
    run:
        # print(CHEM_DICT)
        tmp_chemistry = CHEM_DICT[wildcards.sample]
        STAR_REF = REF_DICT[wildcards.sample]
        # BB_WHITELIST = f"{input.BB_1} {input.BB_2}"
        nBB = sum(1 for line in open(input.BB_WHITELIST)) # get number of bead barcodes for filtered count matrix, `--soloCellFilter`

        SOLOtype = CHEMISTRY_SHEET["STAR.soloType"][tmp_chemistry]
        soloUMI = CHEMISTRY_SHEET["STAR.soloUMI"][tmp_chemistry]
        soloCB = CHEMISTRY_SHEET["STAR.soloCB"][tmp_chemistry]

        print("Using up to " + str(params.MEMLIMIT) + " of memory...")
        shell(
            f"""
            mkdir -p {params.OUTDIR}/{wildcards.sample}/STARsolo

            {params.STAR_EXEC} \
            --runThreadN {threads} \
            --outFileNamePrefix {params.OUTDIR}/{wildcards.sample}/STARsolo/ \
            --outSAMtype BAM SortedByCoordinate \
            --outSAMattributes NH HI nM AS CR UR CB UB GX GN sS sQ sM \
            --readFilesCommand zcat \
            --genomeDir {STAR_REF} \
            --limitBAMsortRAM={params.MEMLIMIT} \
            --readFilesIn {input.FINAL_R2_FQ} {input.FINAL_R1_FQ} \
            --clipAdapterType CellRanger4 \
            --outReadsUnmapped Fastx \
            --outFilterMultimapNmax 50 \
            --outFilterMismatchNoverLmax 0.05 \
            --outFilterMatchNmin 12 \
            --outFilterScoreMinOverLread 0 \
            --outFilterMatchNminOverLread 0 \
            --soloType {SOLOtype} \
            {soloUMI} \
            {soloCB} \
            --soloCBwhitelist {input.BB_WHITELIST} \
            --soloCBmatchWLtype 1MM_multi \
            --soloCellFilter TopCells {nBB} \
            --soloUMIdedup 1MM_CR \
            --soloBarcodeReadLength 0 \
            --soloFeatures Gene GeneFull Velocyto \
            --soloMultiMappers EM
            """
        )
        # --soloCellFilter CellRanger2.2 {nBB} 0.99 10 45000 90000 1 0.01 20000 0.01 10000 \

# compress outputs from STAR (count matrices, cell barcodes, and gene lists)
rule compress_STAR_outs:
    input:
        VELMAT = "{OUTDIR}/{sample}/STARsolo/Solo.out/Velocyto/raw/spliced.mtx",
        GENEMAT = "{OUTDIR}/{sample}/STARsolo/Solo.out/Gene/raw/matrix.mtx",
        GENEFULLMAT = "{OUTDIR}/{sample}/STARsolo/Solo.out/GeneFull/raw/matrix.mtx"
    output:
        VELMAT = "{OUTDIR}/{sample}/STARsolo/Solo.out/Velocyto/raw/spliced.mtx.gz",
        GENEMAT = "{OUTDIR}/{sample}/STARsolo/Solo.out/Gene/raw/matrix.mtx.gz",
        GENEFULLMAT = "{OUTDIR}/{sample}/STARsolo/Solo.out/GeneFull/raw/matrix.mtx.gz"
    params:
        VELDIR = directory("{OUTDIR}/{sample}/STARsolo/Solo.out/Velocyto"),
        GENEDIR = directory("{OUTDIR}/{sample}/STARsolo/Solo.out/Gene"),
        GENEFULLDIR = directory("{OUTDIR}/{sample}/STARsolo/Solo.out/GeneFull")
    threads:
        1
        # config["CORES_LO"]
    # conda:
    #     "STARsolo"
    run:
        shell(
            f"""
            gzip -qf {params.VELDIR}/*/*.tsv {params.VELDIR}/*/*.mtx
            gzip -qf {params.GENEDIR}/*/*.tsv {params.GENEDIR}/*/*.mtx
            gzip -qf {params.GENEFULLDIR}/*/*.tsv {params.GENEFULLDIR}/*/*.mtx
            """
        )

# convert .mtx format to .h5
# SHout out Alex Wolf- https://falexwolf.me/2017/sparse-matrices-with-h5py/
#TODO
rule STAR_mtx2h5:
    input:
        # VELMAT = "{OUTDIR}/{sample}/STARsolo/Solo.out/Velocyto/raw/spliced.mtx.gz",
        GENEMAT = "{OUTDIR}/{sample}/STARsolo/Solo.out/Gene/raw/matrix.mtx.gz",
        GENEFULLMAT = "{OUTDIR}/{sample}/STARsolo/Solo.out/GeneFull/raw/matrix.mtx.gz"
    output:
        # VELMAT = "{OUTDIR}/{sample}/STARsolo/Solo.out/Velocyto/raw_feature_bc_matrix_h5.h5",
        GENEMAT = "{OUTDIR}/{sample}/STARsolo/Solo.out/Gene/raw_feature_bc_matrix_h5.h5",
        GENEFULLMAT = "{OUTDIR}/{sample}/STARsolo/Solo.out/GeneFull/raw_feature_bc_matrix_h5.h5"
    params:
        # VELDIR = directory("{OUTDIR}/{sample}/STARsolo/Solo.out/Velocyto"),
        GENEDIR = directory("{OUTDIR}/{sample}/STARsolo/Solo.out/Gene"),
        GENEFULLDIR = directory("{OUTDIR}/{sample}/STARsolo/Solo.out/GeneFull")
    # conda:
    #     "STARsolo"
    threads:
        1
    run:

        X = scipy.io.mmread(input.GENEFULLMAT)
        bcs = pd.read_csv(
            "features.tsv.gz",
            sep="\t",
            header=None,
            usecols=[1]
        )
        feats = pd.read_csv(
            "features.tsv.gz",
            sep="\t",
            header=None,
            usecols=[1]
        )
        f = h5py.File(output.GENEFULLMAT)
        f.create_dataset('X', data=X)

        f.close()

#TODO add executable
rule indexSortedBAM:
    input:
        SORTEDBAM = '{OUTDIR}/{sample}/STARsolo/Aligned.sortedByCoord.out.bam'
    output:
        BAI = '{OUTDIR}/{sample}/STARsolo/Aligned.sortedByCoord.out.bam.bai'
    threads:
        config['CORES']
    conda:
        "STARsolo"
    shell:
        """
        samtools index -@ {threads} {input.SORTEDBAM}
        """

# Remove reads that don't have a corrected spot/cell barcode with samtools, then remove duplicates w/ **umi-tools**
## High mem usage? Check here! https://umi-tools.readthedocs.io/en/latest/faq.html
#TODO: split bam by strand and by chromosome, then dedup each chr!
rule umitools_dedupBAM:
    input:
        BB = "{OUTDIR}/{sample}/tmp/whitelist.txt",
        SORTEDBAM = '{OUTDIR}/{sample}/Aligned.sortedByCoord.out.bam'
    output:
        DEDUPBAM = '{OUTDIR}/{sample}/Aligned.sortedByCoord.dedup.out.bam',
        TMPBAM = temp('{OUTDIR}/{sample}/tmp.bam')
    params:
        OUTPUT_PREFIX='{OUTDIR}/{sample}/umitools_dedup/{sample}',
        # TMPBAM = '{OUTDIR}/{sample}/tmp.bam'
    threads:
        config['CORES']
        #1
    conda:
        "STARsolo"
    log:
        '{OUTDIR}/{sample}/umitools_dedup/dedup.log'
    shell:
        """
        samtools view -1 -b \
        -@ {threads} \
        --tag-file CB:{input.BB} \
        {input.SORTEDBAM} \
        > {output.TMPBAM}

        samtools index \
        -@ {threads} \
        {output.TMPBAM}

        umi_tools dedup \
        -I {output.TMPBAM} \
        --extract-umi-method=tag \
        --umi-tag=UB \
        --cell-tag=CB \
        --method=unique \
        --per-cell \
        --unmapped-reads=discard \
        --output-stats={params.OUTPUT_PREFIX} \
        --log {log} \
        -S {output.DEDUPBAM}
        """
        # rm {params.TMPBAM}
        # rm (params.TMPBAM).bai

rule umitools_indexDedupBAM:
    input:
        SORTEDBAM = '{OUTDIR}/{sample}/Aligned.sortedByCoord.dedup.out.bam'
    output:
        BAI = '{OUTDIR}/{sample}/Aligned.sortedByCoord.dedup.out.bam.bai'
    threads:
        config['CORES']
    conda:
        "STARsolo"
    shell:
        """
        samtools index -@ {threads} {input.SORTEDBAM}
        """

#############################################
## QC on STAR outputs
#############################################

## qualimap on aligned reads
#TODO- switch to dedup'ed .bam, once I re-write umitools deduplication
rule qualimapQC:
    input:
        SORTEDBAM = '{OUTDIR}/{sample}/STARsolo/Aligned.sortedByCoord.out.bam'
    output:
        qualimapDir = directory('{OUTDIR}/{sample}/qualimap'),
        fastqcReport = '{OUTDIR}/{sample}/qualimap/qualimapReport.html'
    params:
        GENES_GTF = lambda wildcards: GTF_DICT[wildcards.sample]
    threads:
        1
    conda:
        "STARsolo"
    shell:
        """
        mkdir -p {output.qualimapDir}
        cd {output.qualimapDir}

        qualimap rnaseq \
        -bam {input.SORTEDBAM} \
        -gtf {params.GENES_GTF} \
        --sequencing-protocol strand-specific-forward \
        --sorted \
        --java-mem-size=8G \
        -outdir {output.qualimapDir} \
        -outformat html
        """
        # -nt {threads} \

#############################################
## Unmapped read analyses
#############################################

# Run fastqc on unmapped reads; switch names because of STAR weirdness
rule unmapped_fastqc:
    input:
        UNMAPPED1 = '{OUTDIR}/{sample}/STARsolo/Unmapped.out.mate1',
        UNMAPPED2 = '{OUTDIR}/{sample}/STARsolo/Unmapped.out.mate2'
    output:
        UNMAPPED1_FQ = '{OUTDIR}/{sample}/STARsolo/Unmapped.out.mate1.fastq.gz',
        UNMAPPED2_FQ = '{OUTDIR}/{sample}/STARsolo/Unmapped.out.mate2.fastq.gz',
        FQC_DIR = directory('{OUTDIR}/{sample}/Unmapped_fastqc_out')
    params:
        FASTQC_EXEC = config['FASTQC_EXEC']
    threads:
        config['CORES']
    shell:
        """
        mv {input.UNMAPPED1} {input.UNMAPPED2}.fastq
        mv {input.UNMAPPED2} {input.UNMAPPED1}.fastq

        pigz -p{threads} {input.UNMAPPED1}.fastq {input.UNMAPPED2}.fastq

        mkdir -p {output.FQC_DIR}

        {params.FASTQC_EXEC} \
        -o {output.FQC_DIR} \
        -t {threads} \
        -a /home/dwm269/DWM_utils/align_pipes/curio_kallisto/resources/fastqc_adapters.txt \
        {output.UNMAPPED1_FQ} {output.UNMAPPED2_FQ}
        """

# Only BLAST R2, which contains the insert (converts .fq to .fa, then removes the .fa file)
## TODO: change demux step to fastx-collapser
rule blast_unmapped:
    input:
        UNMAPPED2_FQ = '{OUTDIR}/{sample}/STARsolo/Unmapped.out.mate2.fastq.gz'
    output:
        BLAST_R2 = '{OUTDIR}/{sample}/Unmapped.out.mate2_blastResults.txt'
    threads:
        config['CORES']
    params:
        blastDB = config['BLASTDB'],
        FASTX_COLLAPSER = config['FASTX_COLLAPSER'],
        TMP_FA = '{OUTDIR}/{sample}/Unmapped.out.mate2.fa'
    # conda:
    #     "STARsolo"
    shell:
        """
        zcat {input.UNMAPPED2_FQ} | sed -n '1~4s/^@/>/p;2~4p' > {params.TMP_FA}

        echo "Number of unmapped reads: "
        grep -c ">" {params.TMP_FA}

        vsearch --sortbysize {params.TMP_FA} --topn 1000 --output tmp.fa

        blastn -db {params.blastDB}/nt \
        -query tmp.fa \
        -out {output.BLAST_R2} \
        -outfmt '6 qseqid sseqid stitle pident length mismatch gapopen qstart qend sstart send evalue bitscore' \
        -max_target_seqs 5 \
        -num_threads {threads}

        rm {params.TMP_FA}
		"""

# cat {input.UNMAPPED1_FQ} | awk '{{if(NR%4==1) {{printf(">%s\n",substr($0,2));}} else if(NR%4==2) print;}}' > {params.TMP_FA}

#############################################
## Additional files for visualization
#############################################

rule bamToSplitBigWig:
    input:
        BAM = '{OUTDIR}/{sample}/Aligned.sortedByCoord.dedup.out.bam',
        BAI = '{OUTDIR}/{sample}/Aligned.sortedByCoord.dedup.out.bam.bai'
    output:
        POS_BW = '{OUTDIR}/{sample}/Aligned.sortedByCoord.dedup.out_plus.bw',
        MERGED_BW = '{OUTDIR}/{sample}/Aligned.sortedByCoord.dedup.out_merged.bw'
    params:
        BAM2SPLITBW=config['BAM2SPLITBW'],
        STAR_REF = lambda wildcards: REF_DICT[wildcards.sample],
        OUTPUT_DIR = '{OUTDIR}/{sample}'
    threads:
        config['CORES']
    conda:
        "STARsolo"
    shell:
        """
        {params.BAM2SPLITBW} {input.BAM} {threads} {params.OUTPUT_DIR} {STAR_REF}/chrNameLength.txt
        """

#############################################
## kallisto pseudoalignment
#############################################

rule kallisto_align:
    input:
        FINAL_R1_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R1_final.fq.gz',
        FINAL_R2_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R2_final.fq.gz',
        BB = "{OUTDIR}/{sample}/tmp/whitelist.txt"
    output:
        BUSTEXT = temp('{OUTDIR}/{sample}/kb/output.corrected.bus'),
        TRANSCRIPTS = '{OUTDIR}/{sample}/kb/transcripts.txt',
        ECMAP = temp('{OUTDIR}/{sample}/kb/matrix.ec')
    params:
        OUTDIR = config['OUTDIR'],
        STAR_EXEC = config['STAR_EXEC'],
        # STAR_REF = config['STAR_REF'],
        # UMIlen = config['UMIlen'],
        MEMLIMIT = config['MEMLIMIT']
    log:
        '{OUTDIR}/{sample}/kb/kallisto_align.log'
    threads:
        config['CORES']
    priority:
        42
    # conda:
    #     "kallisto1"
    run:
        tmp_chemistry = CHEM_DICT[wildcards.sample]
        KB_IDX = IDX_DICT[wildcards.sample]
        BB_WHITELIST = f"{input.BB}"

        KB_X = CHEMISTRY_SHEET["kb.x"][tmp_chemistry]

        print("Using up to " + str(params.MEMLIMIT) + " of memory...")
        shell(
            f"""
            bash scripts/kb.sh {params.OUTDIR}/{wildcards.sample}/kb \
            {KB_IDX} \
            {BB_WHITELIST} \
            {KB_X} \
            {log} \
            {threads} \
            {params.MEMLIMIT} \
            {input.FINAL_R1_FQ} {input.FINAL_R2_FQ}
            """
        )

rule bus2mat:
    input:
        BUS = '{OUTDIR}/{sample}/kb/output.corrected.bus',
        TRANSCRIPTS = '{OUTDIR}/{sample}/kb/transcripts.txt',
        ECMAP = '{OUTDIR}/{sample}/kb/matrix.ec'
    output:
        MAT = '{OUTDIR}/{sample}/kb/counts_unfiltered/output.mtx'
        # EC = '{OUTDIR}/{sample}/kb/counts_unfiltered/output.ec.txt'
    params:
        MATDIR = directory('{OUTDIR}/{sample}/kb/counts_unfiltered'),
        OUTDIR = config['OUTDIR'],
        BUST_EXEC = config['BUST_EXEC']
    threads:
        1
    run:
        KB_T2G = T2G_DICT[wildcards.sample]

        shell(
        f"""
            mkdir -p {params.MATDIR}

            {params.BUST_EXEC} count \
            --output {params.MATDIR}/ \
            --genemap {KB_T2G} \
            --ecmap {input.ECMAP} \
            --txnames {input.TRANSCRIPTS} \
            --genecounts \
            --umi-gene \
            --em \
            {input.BUS}
            """
        )

rule kallisto_quant_bulk:
    input:
        FINAL_R1_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R1_final_trimmed.fq.gz',
        FINAL_R2_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R2_final_trimmed.fq.gz',
        BB = "{OUTDIR}/{sample}/tmp/whitelist.txt"
    output:
        GENOMEBAM = '{OUTDIR}/{sample}/kb/quant/pseudoalignments.bam'
    params:
        OUTDIR = config['OUTDIR'],
        KALLISTO_EXEC = config['KALLISTO_EXEC'],
        # KB_IDX = config['KB_IDX'],
        MEMLIMIT = config['MEMLIMIT']
    log:
        '{OUTDIR}/{sample}/kb/kallisto_quant_standard.log'
    threads:
        config['CORES']
    run:
        tmp_chemistry = CHEM_DICT[wildcards.sample]
        KB_IDX = IDX_DICT[wildcards.sample]
        BB_WHITELIST = f"{input.BB}"

        STAR_REF = REF_DICT[wildcards.sample] + "/chrNameLength.txt"
        GENES_GTF = GTF_DICT[wildcards.sample]

        shell(
            f"""
            mkdir -p {params.OUTDIR}/{wildcards.sample}/kb/quant

            {params.KALLISTO_EXEC} quant \
            -i {KB_IDX} \
            -o {params.OUTDIR}/{wildcards.sample}/kb/quant/ \
            -t {threads} \
            --fr-stranded \
            --single \
            -l 85 \
            -s 10 \
            --genomebam \
            --chromosomes {params.CHROMOSOMES} \
            --gtf {GENES_GTF} \
            {input.FINAL_R2_FQ}
            """
        )

#############################################
## Post-alignment processing
#############################################
# Initialize a .h5ad object for easy loading into python later

# Preprocessing?
