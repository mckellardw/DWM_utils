########################################################################################################
# STARsolo_10x
#   Snakemake workflow to use STAR to align and quantify bulk RNAseq datasets (total and small RNAseq)
#   v1.0
#   Written by David McKellar
#   Last edited: --/--/--, DWM
########################################################################################################

import pdb
import pandas as pd
import glob

########################################################################################################
# Config file
########################################################################################################
configfile:'config.yaml'
########################################################################################################
# Directories and locations
########################################################################################################
TMPDIR = config['TMPDIR']
OUTDIR = config['OUTDIR']

DATADIR = config['DATADIR']
SRA_DOWNLOAD = config['SRA_DOWNLOAD']

########################################################################################################
# Variables and references
########################################################################################################
SAMPLES = list(pd.read_csv(config['SAMPLE_SHEET'])['sampleID'])

R1_FQS = dict(zip(SAMPLES, list(pd.read_csv(config['SAMPLE_SHEET'])['fastq_R1'])))

# R2_FQS = list(pd.read_csv(config['SAMPLE_SHEET'])['fastq_R2'])
# R2_FQS = dict(zip(SAMPLES, list(pd.read_csv(config['SAMPLE_SHEET'])['fastq_R2'])))

# SRR = dict(zip(SAMPLES, list(pd.read_csv(config['SAMPLE_SHEET'])['SRR'])))

STAR_REF = config['STAR_REF']

########################################################################################################
# Executables
########################################################################################################
STAR_EXEC = config['STAR_EXEC']

########################################################################################################
rule all:
    input:
        # expand('{OUTDIR}/{sample}/Solo.out/Gene/filtered/matrix.mtx', OUTDIR=config['OUTDIR'], sample=SAMPLES),
        # expand('{OUTDIR}/{sample}/Aligned.sortedByCoord.out.bam.bai', OUTDIR=config['OUTDIR'], sample=SAMPLES),
        expand('{OUTDIR}/{sample}/preTrim_fastqc_R1_out', OUTDIR=config['OUTDIR'], sample=SAMPLES), # raw R2 fastQC results
        # expand('{OUTDIR}/{sample}/postTrim_fastqc_R1_out', OUTDIR=config['OUTDIR'], sample=SAMPLES), # adapter/polyA/ployG-trimmed R2 fastQC results
        expand('{OUTDIR}/{sample}/qualimap_out/qualimapReport.html', OUTDIR=config['OUTDIR'], sample=SAMPLES), # alignment QC qith qualimap
        expand('{OUTDIR}/{sample}/Aligned.sortedByCoord.out_plus.bw', OUTDIR=config['OUTDIR'], sample=SAMPLES), # strand-split bigWigs
        # expand('{OUTDIR}/{sample}/ReadsPerGene.out.tab', OUTDIR=config['OUTDIR'], sample=SAMPLES), # count mats
        expand('{OUTDIR}/{sample}/Unmapped_fastqc_out', OUTDIR=config['OUTDIR'], sample=SAMPLES), #fastQC results for unmapped reads
        expand('{OUTDIR}/{sample}/Unmapped.out.mate1_blastResults.txt', OUTDIR=config['OUTDIR'], sample=SAMPLES) # blastn results for unmapped R1 reads


#############################################
## Pre-alignment set up
#############################################
# rule mk_sample_dir:
#     output:
#         sampleDir = directory('{OUTDIR}/{sample}'),
#         # fastqcReport = ''
#     threads:
#         config['CORES']
#     shell:
#         """
#         mkdir -p {output.sampleDir}
#         """

#############################################
## Optional parallel-fastq-dump (if SRR number is passed, instead of .fastq location)
#############################################
# TODO- add multi-SRR number passing (delimit the sample_sheet with ;?)
# rule get_fastqs:
#     output:
#         R1_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R1.fq.gz'
#         # R2_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R2.fq.gz'
#     params:
#         OUT_DIR = DATADIR + '/{sample}/tmp',
#         TMP_DIR = TMPDIR,
#         SRR = lambda wildcards: SRR[wildcards.sample]
#         # SAMPLE = '{sample}'
#     run:
#         if SRA_DOWNLOAD:
#             print("Downloading .fastq's for {params.SRR}")
#             shell("prefetch --max-size 999999999999 {params.SRR}")
#             shell("parallel-fastq-dump --sra-id {params.SRR} --threads {threads} --outdir {params.OUT_DIR} --tmpdir {params.TMP_DIR} --split-files --gzip")
#
#             #rename fastq file(s) with sample IDs
#
#             # update R1_FQS and R2_FQS
#             R1_FQS[wildcards.sample] = "{params.OUT_DIR}/{wildcards.sample}/{params.SRR}_1.fq.gz"
#             # R2_FQS[wildcards.sample] = "{params.OUT_DIR}/{wildcards.sample}/{params.SRR}_2.fq.gz"
#
#             # Update R1.fq location and R2.fq location to sample_sheet
#             #TODO
#         else:
#             print("No SRR number for {wildcards.sample}; proceeding without download.\n")


#############################################
## Trimming and FastQC
#############################################

# Merge .fastq files (in case more than one sesquencing run was performed)
rule merge_fastqs:
    output:
        MERGED_R1_FQ = temp('{OUTDIR}/{sample}/tmp/{sample}_R1.fq.gz')
        # MERGED_R2_FQ = temp('{OUTDIR}/{sample}/tmp/{sample}_R2.fq.gz')
    params:
        TMP_DIR = '{OUTDIR}/{sample}/tmp',
        R1_FQ = lambda wildcards: R1_FQS[wildcards.sample]
        # R2_FQ = lambda wildcards: R2_FQS[wildcards.sample]
    run:
        if len(params.R1_FQ.split(" "))==1: # shell for single fastq input
            shell("cp {params.R1_FQ} {output.MERGED_R1_FQ}")
            # shell("cp {params.R2_FQ} {output.MERGED_R2_FQ}")
        else: # shell enablinging multi-fast input; concatenate inputs
            print("Concatenating",len(params.R1_FQ.split(" ")), ".fastq's for", wildcards.sample)
            shell("mkdir -p {params.TMP_DIR}")
            shell("zcat {params.R1_FQ} > {params.TMP_DIR}/{wildcards.sample}_R1.fq")
            # shell("zcat {params.R2_FQ} > {params.TMP_DIR}/{wildcards.sample}_R2.fq")
            shell("gzip {params.TMP_DIR}/*.fq")

rule preTrim_FastQC_R2:
    input:
        MERGED_R1_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R1.fq.gz'
    output:
        fastqcDir = directory('{OUTDIR}/{sample}/preTrim_fastqc_R1_out'),
        # fastqcReport = ''
    threads:
        config['CORES']
        # min([config['CORES'],8]) # 8 core max based on recommendations from trim_galore authors
    shell:
        """
        mkdir -p {output.fastqcDir}
        cd {output.fastqcDir}

        fastqc \
        --outdir {output.fastqcDir} \
        --threads {threads} \
        {input.MERGED_R1_FQ}
        """

#TODO: log not working...
# rule trimPolyA_R2:
#     input:
#         MERGED_R1_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R1.fq.gz',
#         MERGED_R2_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R2.fq.gz'
#     output:
#         A_TRIMMED_R1_FQ = temp('{OUTDIR}/{sample}/tmp/{sample}_R1_Atrimmed.fq.gz'),
#         A_TRIMMED_R2_FQ = temp('{OUTDIR}/{sample}/tmp/{sample}_R2_Atrimmed.fq.gz')
#         # POLYA_REPORT = '{OUTDIR}/{sample}/cutadapt_polyA_report.txt'
#     params:
#         THREE_PRIME_R2_POLYA = "A"*100,
#         FIVE_PRIME_R2 = "CCCATGTACTCTGCGTTGATACCACTGCTT" #10x TSO sequence #TODO
#     threads:
#         config['CORES']
#         # min([config['CORES'],8]) # 8 core max based on recommendations from trim_galore authors
#     log:
#         '{OUTDIR}/{sample}/cutadapt_polyA_report.txt'
#     shell:
#         """
#         # TSO & polyA trimming
#         cutadapt \
#         --minimum-length 10 \
#         -A {params.THREE_PRIME_R2_POLYA} \
#  		-G {params.FIVE_PRIME_R2} \
#         --pair-filter=any \
#  		-o {output.A_TRIMMED_R1_FQ} \
#         -p {output.A_TRIMMED_R2_FQ} \
#         --cores {threads} \
#         {input.MERGED_R1_FQ} {input.MERGED_R2_FQ}
#         """

rule trimgalore:
    input:
        MERGED_R1_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R1.fq.gz'
    output:
        # OUTDIR = directory('{OUTDIR}/{sample}/tmp/'),
        A_TRIMMED_R1 = '{OUTDIR}/{sample}/tmp/{sample}_R1.fq.gz'
        # A_TRIMMED_R2_FQ = temp('{OUTDIR}/{sample}/tmp/{sample}_R2_Atrimmed.fq.gz')
    params:
        OUTDIR = '{OUTDIR}/{sample}/tmp/'
    threads:
        # config['CORES']
        min([config['CORES'],8]) # 8 core max based on recommendations from trim_galore authors
    shell:
        """
        # TSO & polyA trimming
        trim_galore \
        --length 10 \
        --2colour \
 		-o {params.OUTDIR} \
        --cores {threads} \
        {input.MERGED_R1_FQ}
        """
 # {input.MERGED_R2_FQ}

#Additional trimming step, just for 2-color Illumina chemistries (NextSeq, etc.)
#TODO: log not working...
# rule trimPolyG_R1:
#     input:
#         A_TRIMMED_R1_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R1.fq.gz'
#         # A_TRIMMED_R2_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R2_Atrimmed.fq.gz'
#     output:
#         FINAL_R1_FQ = temp('{OUTDIR}/{sample}/tmp/{sample}_R1_final.fq.gz')
#         # FINAL_R2_FQ = temp('{OUTDIR}/{sample}/tmp/{sample}_R2_final.fq.gz'),
#         # POLYG_REPORT = '{OUTDIR}/{sample}/cutadapt_polyG_report.txt'
#     params:
#         THREE_PRIME_R1_POLYG = "G"*100
#     threads:
#         config['CORES']
#         # min([config['CORES'],8]) # 8 core max based on recommendations from trim_galore authors
#     log:
#         '{OUTDIR}/{sample}/cutadapt_polyG_report.txt' #TODO - doesn't work...
#     shell:
#         """
#         cutadapt \
#         --minimum-length 10 \
#         -A {params.THREE_PRIME_R1_POLYG} \
#         --pair-filter=any \
#  		-o {output.FINAL_R1_FQ} \
#         --cores {threads} \
#         {input.A_TRIMMED_R1_FQ}
#         """

##TODO
# rule postTrim_FastQC_R1:
#     input:
#         FINAL_R1_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R1_final.fq.gz'
#     output:
#         fastqcDir = directory('{OUTDIR}/{sample}/postTrim_fastqc_R1_out'),
#         # fastqcReport = ''
#     threads:
#         config['CORES']
#         # min([config['CORES'],8]) # 8 core max based on recommendations from trim_galore authors
#     shell:
#         """
#         mkdir -p {output.fastqcDir}
#         cd {output.fastqcDir}
#
#         fastqc \
#         --outdir {output.fastqcDir} \
#         --threads {threads} \
#         {input.FINAL_R1_FQ}
#         """

#############################################
## Alignment
#############################################
# Make output directory, align fastqs, and generate raw/filtered feature/cell-barcode matrices
#   Info for STARsolo command line paramaters: https://github.com/alexdobin/STAR/blob/master/docs/STARsolo.md

#TODO- update alignment parameters for standard chemistries?
rule STARsolo_align:
    input:
        FINAL_R1_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R1.fq.gz', # _final
        # FINAL_R2_FQ = '{OUTDIR}/{sample}/tmp/{sample}_R2_final.fq.gz'
    output: #TODO- add more output files?
        SORTEDBAM = '{OUTDIR}/{sample}/Aligned.sortedByCoord.out.bam',
        UNMAPPED1 = '{OUTDIR}/{sample}/Unmapped.out.mate1'
        # UNMAPPED2 = '{OUTDIR}/{sample}/Unmapped.out.mate2',
        # COUNTS = '{OUTDIR}/{sample}/ReadsPerGene.out.tab'
    params:
        # R1_FQ = lambda wildcards: R1_FQS[wildcards.sample],
        # R2_FQ = lambda wildcards: R2_FQS[wildcards.sample],
        OUTDIR = config['OUTDIR'],
        STAR_EXEC = config['STAR_EXEC'],
        STAR_REF = config['STAR_REF'],
        # UMIlen = config['UMIlen'],
        MEMLIMIT = config['MEMLIMIT']
    threads:
        config['CORES']
    shell: # TODO- convert to bash script?
        """
        mkdir -p {params.OUTDIR}/{wildcards.sample}

        {params.STAR_EXEC} \
        --runThreadN {threads} \
        --outFileNamePrefix {params.OUTDIR}/{wildcards.sample}/ \
        --outSAMtype BAM SortedByCoordinate \
        --outSAMattributes NH HI NM MD AS nM jM jI XS \
        --readFilesCommand zcat \
        --genomeDir {params.STAR_REF} \
        --genomeLoad LoadAndKeep \
        --limitBAMsortRAM={params.MEMLIMIT} \
        --readFilesIn {input.FINAL_R1_FQ} \
        --outReadsUnmapped Fastx \
        --outFilterMismatchNoverLmax 0.05 \
        --outFilterMatchNmin 16 \
        --outFilterScoreMinOverLread 0 \
        --outFilterMatchNminOverLread 0 \
        --outFilterMultimapNmax 50
        """
        # gzip -qf {output.GENE}/raw/*
        # gzip -qf {output.GENE}/filtered/*
        #
        # gzip -qf {output.GENEFULL}/raw/*
        # gzip -qf {output.GENEFULL}/filtered/*
        #
        # gzip -qf {output.SJ}/raw/*
        #
        # gzip -qf {output.VEL}/raw/*
        # gzip -qf {output.VEL}/filtered/*


#TODO this is extraneous
rule indexBAM:
    input:
        SORTEDBAM = '{OUTDIR}/{sample}/Aligned.sortedByCoord.out.bam'
    output:
        BAI = '{OUTDIR}/{sample}/Aligned.sortedByCoord.out.bam.bai'
    threads:
        config['CORES']
    shell:
        """
        samtools index -@ {threads} {input.SORTEDBAM}
        """

#############################################
## qualimap on aligned reads
#############################################
rule qualimapQC:
    input:
        SORTEDBAM = '{OUTDIR}/{sample}/Aligned.sortedByCoord.out.bam'
    output:
        qualimapDir = directory('{OUTDIR}/{sample}/qualimap_out'),
        fastqcReport = '{OUTDIR}/{sample}/qualimap_out/qualimapReport.html'
    params:
        GENES_GTF = config['GENES_GTF']
    threads:
        config['CORES']
    shell:
        """
        mkdir -p {output.qualimapDir}
        cd {output.qualimapDir}

        qualimap rnaseq \
        -bam {input.SORTEDBAM} \
        -gtf {params.GENES_GTF} \
        --sequencing-protocol strand-specific-forward \
        --sorted \
        --java-mem-size=4G \
        -outdir {output.qualimapDir} \
        -outformat html
        """

#############################################
## Unmapped read analyses
#############################################

# Run fastqc on unmapped reads; switch names because of STAR weirdness
rule unmapped_fastqc:
    input:
        UNMAPPED1 = '{OUTDIR}/{sample}/Unmapped.out.mate1'
        # UNMAPPED2 = '{OUTDIR}/{sample}/Unmapped.out.mate2'
    output:
        UNMAPPED1_FQ = '{OUTDIR}/{sample}/Unmapped.out.mate1.fastq',
        # UNMAPPED2_FQ = '{OUTDIR}/{sample}/Unmapped.out.mate2.fastq',
        FQC_DIR = directory('{OUTDIR}/{sample}/Unmapped_fastqc_out')
    params:
        FASTQC_EXEC = config['FASTQC_EXEC']
    threads:
        config['CORES']
    shell:
        # mv {input.UNMAPPED1} {output.UNMAPPED2_FQ}
        # mv {input.UNMAPPED2} {output.UNMAPPED1_FQ}
        """
        mv {input.UNMAPPED1} {output.UNMAPPED1_FQ}

        mkdir -p {output.FQC_DIR}

        {params.FASTQC_EXEC} -o {output.FQC_DIR} -t {threads} {output.UNMAPPED1_FQ}
        """
        # {output.UNMAPPED2_FQ}

# Only BLAST R1, which contains the insert (converts .fq to .fa, then removes the .fa file)
## TODO: change demux step to fastx-collapser
rule blast_unmapped:
    input:
        UNMAPPED1_FQ = '{OUTDIR}/{sample}/Unmapped.out.mate1.fastq'
    output:
        BLAST_R1 = '{OUTDIR}/{sample}/Unmapped.out.mate1_blastResults.txt'
    threads:
        config['CORES']
    params:
        blastDB = config['BLASTDB'],
        FASTX_COLLAPSER = config['FASTX_COLLAPSER'],
        TMP_FA = '{OUTDIR}/{sample}/Unmapped.out.mate1'
    shell:
        """
        sed -n '1~4s/^@/>/p;2~4p' {input.UNMAPPED1_FQ} > {params.TMP_FA}

        echo "Number of unmapped reads: "
        grep -c ">" {params.TMP_FA}

        vsearch --sortbysize {params.TMP_FA} --topn 1000 --output tmp.fa

        blastn -db {params.blastDB}/nt \
        -query tmp.fa \
        -out {output.BLAST_R1} \
        -outfmt '6 qseqid sseqid stitle pident length mismatch gapopen qstart qend sstart send evalue bitscore' \
        -max_target_seqs 5 \
        -num_threads {threads}

        rm {params.TMP_FA}
		"""

# cat {input.UNMAPPED1_FQ} | awk '{{if(NR%4==1) {{printf(">%s\n",substr($0,2));}} else if(NR%4==2) print;}}' > {params.TMP_FA}


#############################################
## Additional files for visualization
#############################################

rule bamToSplitBigWig:
    input:
        BAM = '{OUTDIR}/{sample}/Aligned.sortedByCoord.out.bam',
        BAI = '{OUTDIR}/{sample}/Aligned.sortedByCoord.out.bam.bai'
    output:
        POS_BW = '{OUTDIR}/{sample}/Aligned.sortedByCoord.out_plus.bw',
    params:
        BAM2SPLITBW=config['BAM2SPLITBW'],
        STAR_REF = config['STAR_REF'],
        OUTPUT_DIR = '{OUTDIR}/{sample}'
    threads:
        config['CORES']
    shell:
        """
        {params.BAM2SPLITBW} {input.BAM} {threads} {params.OUTPUT_DIR} {STAR_REF}/chrNameLength.txt
        """
